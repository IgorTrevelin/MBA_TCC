{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c53d12-fbf5-4a92-b1a7-d3f593e22769",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Required Modules Loading and Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eff761e-3d23-48bb-a401-a840a578cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "from random import seed\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import combinations_with_replacement\n",
    "from inc import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ef3439-dbdc-4c2c-a4fb-95d2bf966b17",
   "metadata": {},
   "source": [
    "# Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e49a0594-1aa2-4123-83bd-fe725c12341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset.csv', index_col=0)\n",
    "data.index = pd.to_datetime(data.index, format='%Y-%m-%d')\n",
    "index = pd.date_range(start=data.index.min(), end=data.index.max(), freq='D')\n",
    "data.set_index(index, inplace=True)\n",
    "data[['Close', 'Open', 'High', 'Low']] = data[['Close', 'Open', 'High', 'Low']].replace(',', '', regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8247e225-cbf0-465a-b54b-33ba1d2cfd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1768 entries, 2013-03-01 to 2018-01-01\n",
      "Freq: D\n",
      "Data columns (total 18 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   Close                               1768 non-null   float64\n",
      " 1   Open                                1768 non-null   float64\n",
      " 2   High                                1768 non-null   float64\n",
      " 3   Low                                 1768 non-null   float64\n",
      " 4   Bitcoin Total Transaction Fees USD  1768 non-null   float64\n",
      " 5   Bitcoin USD Exchange Trade Volume   1768 non-null   float64\n",
      " 6   Bitcoin Hash Rate                   1768 non-null   float64\n",
      " 7   Bitcoin Cost Per Transaction        1768 non-null   float64\n",
      " 8   Bitcoin Number of Transactions      1768 non-null   float64\n",
      " 9   Crude Oil                           1768 non-null   float64\n",
      " 10  S&P500 Future                       1768 non-null   float64\n",
      " 11  Gold                                1768 non-null   float64\n",
      " 12  Heating Oil                         1768 non-null   float64\n",
      " 13  Coffee                              1768 non-null   float64\n",
      " 14  Natural Gas                         1768 non-null   float64\n",
      " 15  NASDAQ Future                       1768 non-null   float64\n",
      " 16  Silver                              1768 non-null   float64\n",
      " 17  DAX Index                           1768 non-null   float64\n",
      "dtypes: float64(18)\n",
      "memory usage: 262.4 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0c516c-9a6c-403b-9d94-ef08d2d8f02c",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a3aa533-54fa-4182-bee5-9780a72934b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Direction'] = (data['Close'].diff() >= 0).astype(int)\n",
    "data1 = data.loc['2013-08-19':'2016-07-19',:].copy()\n",
    "data2 = data.loc['2013-04-01':'2017-04-01',:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d72cf653-629b-4828-87a1-f401473a1889",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_features = (\n",
    "    'Close',\n",
    "    'Open',\n",
    "    'High',\n",
    "    'Low',\n",
    "    'Direction',\n",
    "    'Bitcoin Total Transaction Fees USD',\n",
    "    'Bitcoin USD Exchange Trade Volume',\n",
    "    'Bitcoin Hash Rate',\n",
    "    'Bitcoin Cost Per Transaction',\n",
    "    'Bitcoin Number of Transactions'\n",
    ")\n",
    "\n",
    "data1_with_lags = calc_lags(data1, lag_features)\n",
    "data2_with_lags = calc_lags(data2, lag_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5715301-deb1-4312-a63b-31aa2aa104f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wma_features = (\n",
    "    'Close',\n",
    "    'Open',\n",
    "    'High',\n",
    "    'Low',\n",
    "    'Bitcoin Total Transaction Fees USD',\n",
    "    'Bitcoin USD Exchange Trade Volume',\n",
    "    'Bitcoin Hash Rate',\n",
    "    'Bitcoin Cost Per Transaction',\n",
    "    'Bitcoin Number of Transactions',\n",
    "    'Crude Oil',\n",
    "    'S&P500 Future',\n",
    "    'Gold',\n",
    "    'Silver',\n",
    "    'Coffee',\n",
    "    'Heating Oil',\n",
    "    'Natural Gas',\n",
    "    'NASDAQ Future',\n",
    "    'DAX Index'\n",
    ")\n",
    "\n",
    "data1_with_wma = calc_wma(data1_with_lags, wma_features, 30)\n",
    "data2_with_wma = calc_wma(data2_with_lags, wma_features, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e8dbc35-e5b2-4ea0-b016-49d769280a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1_with_wma.dropna().copy()\n",
    "data2 = data2_with_wma.dropna().copy()\n",
    "to_drop = list(set(lag_features + wma_features))\n",
    "to_drop.remove('Open')\n",
    "to_drop.remove('Direction')\n",
    "data1.drop(to_drop, axis=1, inplace=True)\n",
    "data2.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd93ee1-9f6f-4a16-9db9-7758e8f576eb",
   "metadata": {},
   "source": [
    "# Data Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bedd1261-fbe2-47c3-92b8-d31ce180ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Direction'\n",
    "\n",
    "# ds_int1 = data.loc['2013-08-19':'2016-07-19',:]\n",
    "# ds_int2 = data.loc['2013-04-01':'2017-04-01',:]\n",
    "\n",
    "X_int1 = data1.drop(target, axis=1).to_numpy()\n",
    "y_int1 = data1[target].to_numpy()\n",
    "\n",
    "X_int2 = data2.drop(target, axis=1).to_numpy()\n",
    "y_int2 = data2[target].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c9899c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_int1: (1036, 89)\n",
      "y_int1: (1036,)\n",
      "X_int2: (1432, 89)\n",
      "y_int2: (1432,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_int1: {X_int1.shape}')\n",
    "print(f'y_int1: {y_int1.shape}')\n",
    "print(f'X_int2: {X_int2.shape}')\n",
    "print(f'y_int2: {y_int2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd41aa1b-0a39-432a-b143-f5d31f7d1954",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Experiments Interval 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5860462a-0db7-422e-83bc-6e42148094bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (829, 89)\n",
      "y_train: (829,)\n",
      "X_test: (207, 89)\n",
      "y_test: (207,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_int1, y_int1)\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'y_train: {y_train.shape}')\n",
    "print(f'X_test: {X_test.shape}')\n",
    "print(f'y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bbe2f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(100)\n",
    "np.random.seed(100)\n",
    "\n",
    "\n",
    "def CCSA_filter(X_train, y_train, max_iter=100, max_saturation=0):\n",
    "    def f(i, j):\n",
    "        mi = mutual_info_regression(i.reshape(-1, 1), j)[0]\n",
    "        corr, _ = pearsonr(i, j)\n",
    "\n",
    "        return mi + abs(corr)\n",
    "\n",
    "    f_values = {}\n",
    "    ncols = X_train.shape[1]\n",
    "\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(f)(X_train[:, i], X_train[:, j])\n",
    "        for i in range(ncols - 1)\n",
    "        for j in range(i + 1, ncols)\n",
    "    )\n",
    "\n",
    "    index = 0\n",
    "    for i in range(ncols - 1):\n",
    "        for j in range(i + 1, ncols):\n",
    "            f_values[(i, j)] = results[index]\n",
    "            f_values[(j, i)] = results[index]\n",
    "            index += 1\n",
    "\n",
    "    results = Parallel(n_jobs=n_jobs)(delayed(f)(X_train[:, i], y_train) for i in range(ncols))\n",
    "\n",
    "    index = 0\n",
    "    for i in range(ncols):\n",
    "        f_values[(\"target\", i)] = results[index]\n",
    "        index += 1\n",
    "\n",
    "    def ccsa_filter_fitness(solution):\n",
    "        selected = [i for i in range(len(solution)) if solution[i] >= 0]\n",
    "        \n",
    "        f_features_target = 0\n",
    "        for idx in selected:\n",
    "            m = f_values[(\"target\", idx)]\n",
    "            f_features_target += m\n",
    "\n",
    "        f_features = 0\n",
    "        count = 0\n",
    "        for i in range(len(selected) - 1):\n",
    "            for j in range(i + 1, len(selected)):\n",
    "                count += 1\n",
    "                m = f_values[(selected[i], selected[j])]\n",
    "                f_features += m\n",
    "\n",
    "        return -1 * (f_features_target - f_features)\n",
    "\n",
    "    sol, _ = CCSA(X_train.shape[1], 30, ccsa_filter_fitness, max_iter, max_saturation)\n",
    "    return [i for i in range(len(sol)) if sol[i] >= 0], _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c15bcaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Close_L1', 'High_L1', 'Low_L1',\n",
       "       'Bitcoin Total Transaction Fees USD_L1',\n",
       "       'Bitcoin USD Exchange Trade Volume_L1', 'Close_L2', 'Low_L2',\n",
       "       'Bitcoin USD Exchange Trade Volume_L2', 'Bitcoin Hash Rate_L2',\n",
       "       'Bitcoin Cost Per Transaction_L2', 'Bitcoin Number of Transactions_L2',\n",
       "       'Open_L3', 'High_L3', 'Low_L3', 'Direction_L3',\n",
       "       'Bitcoin USD Exchange Trade Volume_L3', 'Bitcoin Hash Rate_L3',\n",
       "       'Bitcoin Number of Transactions_L3', 'Open_L4', 'High_L4', 'Low_L4',\n",
       "       'Bitcoin Total Transaction Fees USD_L4', 'Bitcoin Hash Rate_L4',\n",
       "       'Bitcoin Number of Transactions_L4', 'Open_L5', 'High_L5', 'Low_L5',\n",
       "       'Bitcoin Total Transaction Fees USD_L5',\n",
       "       'Bitcoin Cost Per Transaction_L5', 'High_L6', 'Low_L6', 'Direction_L6',\n",
       "       'Bitcoin Number of Transactions_L6', 'Close_L7', 'Open_L7', 'Low_L7',\n",
       "       'Bitcoin USD Exchange Trade Volume_L7', 'Bitcoin Hash Rate_L7',\n",
       "       'Bitcoin Number of Transactions_L7', 'Close_WMA30',\n",
       "       'Bitcoin Hash Rate_WMA30', 'Bitcoin Cost Per Transaction_WMA30',\n",
       "       'Bitcoin Number of Transactions_WMA30', 'Gold_WMA30', 'Silver_WMA30',\n",
       "       'Coffee_WMA30', 'Natural Gas_WMA30', 'NASDAQ Future_WMA30'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_selected, f_hist = CCSA_filter(X_train, y_train, 3000, 50)\n",
    "data1.drop(target, axis=1).columns[filter_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d778394e-ac4d-44b2-966d-4f7588a52e55",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da52a5fc-2945-4702-a2d2-665f1082ad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(kernel='poly', max_iter=5e5)\n",
    ")\n",
    "\n",
    "params, _ = find_best_params(\n",
    "    pipe,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    {\n",
    "        'svc__degree': np.arange(1,5),\n",
    "        'svc__gamma': [1/X_train.shape[1]] + list(np.arange(.1, 1.1, .1)),\n",
    "        'svc__C': [.5, 1, 5, 10]\n",
    "    }\n",
    ")\n",
    "\n",
    "pipe = pipe.set_params(**params)\n",
    "\n",
    "tests = run_tests(pipe, X_train, y_train, X_test, y_test, 1)\n",
    "tests.insert(0, 'Interval 1')\n",
    "tests.insert(1, params)\n",
    "tests.insert(2, 'All Features')\n",
    "results.append(tests)\n",
    "\n",
    "params, _ = find_best_params(\n",
    "    pipe,\n",
    "    X_train[:,filter_selected],\n",
    "    y_train,\n",
    "    X_test[:,filter_selected],\n",
    "    y_test,\n",
    "    {\n",
    "        'svc__degree': np.arange(1,5),\n",
    "        'svc__gamma': [1/len(filter_selected)] + list(np.arange(.1, 1.1, .1)),\n",
    "        'svc__C': [.5, 1, 5, 10]\n",
    "    }\n",
    ")\n",
    "\n",
    "pipe = pipe.set_params(**params)\n",
    "\n",
    "tests = run_tests(pipe, X_train[:,filter_selected], y_train, X_test[:,filter_selected], y_test, 1)\n",
    "tests.insert(0, 'Interval 1')\n",
    "tests.insert(1, params)\n",
    "tests.insert(2, 'CCSA Filter')\n",
    "results.append(tests)\n",
    "\n",
    "dump_results(results, 'svm_int1.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d241aa4-8971-4566-a1af-7b57e3e7dd75",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68b9ec85-e501-44cd-a515-e82293e8b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "params, _ = find_best_params(\n",
    "    model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    {\n",
    "        'max_depth': np.arange(1, 20),\n",
    "        'n_estimators': [20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    }\n",
    ")\n",
    "\n",
    "model.set_params(**params)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "tests = run_tests(model, X_train, y_train, X_test, y_test, 50)\n",
    "tests.insert(0, 'Interval 1')\n",
    "tests.insert(1, params)\n",
    "tests.insert(2, 'All Features')\n",
    "results.append(tests)\n",
    "\n",
    "params, _ = find_best_params(\n",
    "    model,\n",
    "    X_train[:,filter_selected],\n",
    "    y_train,\n",
    "    X_test[:,filter_selected],\n",
    "    y_test,\n",
    "    {\n",
    "        'max_depth': np.arange(1, 20),\n",
    "        'n_estimators': [20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    }\n",
    ")\n",
    "\n",
    "model.set_params(**params)\n",
    "\n",
    "tests = run_tests(model, X_train[:,filter_selected], y_train, X_test[:,filter_selected], y_test, 50)\n",
    "tests.insert(0, 'Interval 1')\n",
    "tests.insert(1, params)\n",
    "tests.insert(2, 'CCSA Filter')\n",
    "results.append(tests)\n",
    "\n",
    "dump_results(results, 'rnd_forest_int1.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66d812a-b971-444d-a95c-4b5430cc5703",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dea1437f-91e6-42ef-98ac-1989d195b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "\n",
    "params, _ = find_best_params(\n",
    "    model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    {\n",
    "        'max_depth': np.arange(1, 20),\n",
    "        'n_estimators': [20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    }\n",
    ")\n",
    "\n",
    "model.set_params(**params)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "tests = run_tests(model, X_train, y_train, X_test, y_test, 50)\n",
    "tests.insert(0, 'Interval 1')\n",
    "tests.insert(1, params)\n",
    "tests.insert(2, 'All Features')\n",
    "results.append(tests)\n",
    "\n",
    "params, _ = find_best_params(\n",
    "    model,\n",
    "    X_train[:,filter_selected],\n",
    "    y_train,\n",
    "    X_test[:,filter_selected],\n",
    "    y_test,\n",
    "    {\n",
    "        'max_depth': np.arange(1, 20),\n",
    "        'n_estimators': [20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    }\n",
    ")\n",
    "\n",
    "model.set_params(**params)\n",
    "\n",
    "tests = run_tests(model, X_train[:,filter_selected], y_train, X_test[:,filter_selected], y_test, 50)\n",
    "tests.insert(0, 'Interval 1')\n",
    "tests.insert(1, params)\n",
    "tests.insert(2, 'CCSA Filter')\n",
    "results.append(tests)\n",
    "\n",
    "dump_results(results, 'extrees_int1.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6e1ce7-9f2e-4e44-84f5-9dff6089667e",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39d75647-8308-42d0-b58d-3828e1ffd653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "n_layers = np.arange(2) + 1\n",
    "n_neurons = np.arange(0, 35, 5) + 5\n",
    "epochs = [20, 100, 200, 300, 400, 500]\n",
    "combinations = []\n",
    "\n",
    "for layers in n_layers:\n",
    "    combinations.extend(combinations_with_replacement(n_neurons, int(layers)))\n",
    "    \n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    MLPClassifier(solver='adam', activation='tanh', learning_rate='adaptive')\n",
    ")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    \n",
    "    params, _ = find_best_params(\n",
    "        pipe,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        {\n",
    "            'mlpclassifier__hidden_layer_sizes': combinations,\n",
    "            'mlpclassifier__max_iter': epochs\n",
    "        }\n",
    "    )\n",
    "\n",
    "    pipe = pipe.set_params(**params)\n",
    "\n",
    "    tests = run_tests(pipe, X_train, y_train, X_test, y_test, 50)\n",
    "    tests.insert(0, 'Interval 1')\n",
    "    tests.insert(1, params)\n",
    "    tests.insert(2, 'All Features')\n",
    "    results.append(tests)\n",
    "    \n",
    "    params, _ = find_best_params(\n",
    "        pipe,\n",
    "        X_train[:,filter_selected],\n",
    "        y_train,\n",
    "        X_test[:,filter_selected],\n",
    "        y_test,\n",
    "        {\n",
    "            'mlpclassifier__hidden_layer_sizes': combinations,\n",
    "            'mlpclassifier__max_iter': epochs\n",
    "        }\n",
    "    )\n",
    "\n",
    "    pipe = pipe.set_params(**params)\n",
    "    \n",
    "    tests = run_tests(pipe, X_train[:,filter_selected], y_train, X_test[:,filter_selected], y_test, 50)\n",
    "    tests.insert(0, 'Interval 1')\n",
    "    tests.insert(1, params)\n",
    "    tests.insert(2, 'CCSA Filter')\n",
    "    results.append(tests)\n",
    "\n",
    "    dump_results(results, 'mlp_int1.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54afe8c-369e-4225-95ed-ed3959bb5d8e",
   "metadata": {},
   "source": [
    "### Ensemble 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6f348d6-c236-4c78-ba33-870d66f8a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "n_layers = np.arange(2) + 1\n",
    "n_neurons = np.arange(0, 35, 5) + 5\n",
    "epochs = [20, 100, 200, 300, 400, 500]\n",
    "combinations = []\n",
    "\n",
    "for layers in n_layers:\n",
    "    combinations.extend(combinations_with_replacement(n_neurons, int(layers)))\n",
    "    \n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    Ensemble1()\n",
    ")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    params, _ = find_best_params(\n",
    "        pipe,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        {\n",
    "            'ensemble1__mlp_hidden_layers_sizes': combinations,\n",
    "            'ensemble1__epochs': epochs\n",
    "        }\n",
    "    )\n",
    "\n",
    "    pipe = pipe.set_params(**params)\n",
    "\n",
    "    tests = run_tests(pipe, X_train, y_train, X_test, y_test, 50)\n",
    "    tests.insert(0, 'Interval 1')\n",
    "    tests.insert(1, params)\n",
    "    tests.insert(2, 'All Features')\n",
    "    results.append(tests)\n",
    "    \n",
    "    params, _ = find_best_params(\n",
    "        pipe,\n",
    "        X_train[:,filter_selected],\n",
    "        y_train,\n",
    "        X_test[:,filter_selected],\n",
    "        y_test,\n",
    "        {\n",
    "            'ensemble1__mlp_hidden_layers_sizes': combinations,\n",
    "            'ensemble1__epochs': epochs\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    pipe = pipe.set_params(**params)\n",
    "    \n",
    "    tests = run_tests(pipe, X_train[:,filter_selected], y_train, X_test[:,filter_selected], y_test, 50)\n",
    "    tests.insert(0, 'Interval 1')\n",
    "    tests.insert(1, params)\n",
    "    tests.insert(2, 'CCSA Filter')\n",
    "    results.append(tests)\n",
    "    \n",
    "    dump_results(results, 'ensemble1_int1.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cd6a0a-96e5-4812-a559-689bf9cdc6ad",
   "metadata": {},
   "source": [
    "### Ensemble 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbaf907e-dbd7-4acb-a0a6-fc33ec93af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "n_layers = np.arange(2) + 1\n",
    "n_neurons = np.arange(0, 35, 5) + 5\n",
    "epochs = [20, 100, 200, 300, 400, 500]\n",
    "combinations = []\n",
    "\n",
    "for layers in n_layers:\n",
    "    combinations.extend(combinations_with_replacement(n_neurons, int(layers)))\n",
    "    \n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    Ensemble2()\n",
    ")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    params, _ = find_best_params(\n",
    "        pipe,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        {\n",
    "            'ensemble2__mlp_hidden_layers_sizes': combinations,\n",
    "            'ensemble2__epochs': epochs\n",
    "        }\n",
    "    )\n",
    "\n",
    "    pipe = pipe.set_params(**params)\n",
    "\n",
    "    tests = run_tests(pipe, X_train, y_train, X_test, y_test, 50)\n",
    "    tests.insert(0, 'Interval 1')\n",
    "    tests.insert(1, params)\n",
    "    tests.insert(2, 'All Features')\n",
    "    results.append(tests)\n",
    "    \n",
    "    params, _ = find_best_params(\n",
    "        pipe,\n",
    "        X_train[:,filter_selected],\n",
    "        y_train,\n",
    "        X_test[:,filter_selected],\n",
    "        y_test,\n",
    "        {\n",
    "            'ensemble2__mlp_hidden_layers_sizes': combinations,\n",
    "            'ensemble2__epochs': epochs\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    pipe = pipe.set_params(**params)\n",
    "    \n",
    "    tests = run_tests(pipe, X_train[:,filter_selected], y_train, X_test[:,filter_selected], y_test, 50)\n",
    "    tests.insert(0, 'Interval 1')\n",
    "    tests.insert(1, params)\n",
    "    tests.insert(2, 'CCSA Filter')\n",
    "    results.append(tests)\n",
    "    \n",
    "    dump_results(results, 'ensemble2_int1.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b75a93-563f-4e8b-a64d-d128914bea5d",
   "metadata": {},
   "source": [
    "# Experiments Interval 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e27f111-cbcf-426b-ae4f-aaf70e127ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1146, 89)\n",
      "y_train: (1146,)\n",
      "X_test: (286, 89)\n",
      "y_test: (286,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_int2, y_int2)\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'y_train: {y_train.shape}')\n",
    "print(f'X_test: {X_test.shape}')\n",
    "print(f'y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1430e3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'Close_L1', 'Low_L1', 'Bitcoin USD Exchange Trade Volume_L1',\n",
       "       'High_L2', 'Direction_L2', 'Bitcoin USD Exchange Trade Volume_L2',\n",
       "       'Bitcoin Hash Rate_L2', 'Close_L3', 'Open_L3', 'High_L3',\n",
       "       'Bitcoin Total Transaction Fees USD_L3',\n",
       "       'Bitcoin Cost Per Transaction_L3', 'High_L4',\n",
       "       'Bitcoin Total Transaction Fees USD_L4',\n",
       "       'Bitcoin Cost Per Transaction_L4', 'Bitcoin Number of Transactions_L4',\n",
       "       'Open_L5', 'High_L5', 'Direction_L5', 'Bitcoin Hash Rate_L5',\n",
       "       'Close_L6', 'Direction_L6', 'Bitcoin USD Exchange Trade Volume_L6',\n",
       "       'Bitcoin Hash Rate_L6', 'Bitcoin Cost Per Transaction_L6', 'Close_L7',\n",
       "       'High_L7', 'Low_L7', 'Direction_L7',\n",
       "       'Bitcoin Total Transaction Fees USD_L7',\n",
       "       'Bitcoin USD Exchange Trade Volume_L7',\n",
       "       'Bitcoin Number of Transactions_L7', 'Open_WMA30',\n",
       "       'Bitcoin Total Transaction Fees USD_WMA30',\n",
       "       'Bitcoin USD Exchange Trade Volume_WMA30',\n",
       "       'Bitcoin Cost Per Transaction_WMA30',\n",
       "       'Bitcoin Number of Transactions_WMA30', 'Crude Oil_WMA30',\n",
       "       'S&P500 Future_WMA30', 'Silver_WMA30', 'Heating Oil_WMA30',\n",
       "       'NASDAQ Future_WMA30', 'DAX Index_WMA30'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_selected, f_hist = CCSA_filter(X_train, y_train, 3000, 50)\n",
    "data2.drop(target, axis=1).columns[filter_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a05a4b",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61a0c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(kernel='poly', max_iter=5e5)\n",
    ")\n",
    "\n",
    "params, _ = find_best_params(\n",
    "    pipe,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    {\n",
    "        'svc__degree': np.arange(1,5),\n",
    "        'svc__gamma': [1/X_train.shape[1]] + list(np.arange(.1, 1.1, .1)),\n",
    "        'svc__C': [.5, 1, 5, 10]\n",
    "    }\n",
    ")\n",
    "\n",
    "pipe = pipe.set_params(**params)\n",
    "\n",
    "tests = run_tests(pipe, X_train, y_train, X_test, y_test, 1)\n",
    "tests.insert(0, 'Interval 2')\n",
    "tests.insert(1, params)\n",
    "tests.insert(2, 'All Features')\n",
    "results.append(tests)\n",
    "\n",
    "params, _ = find_best_params(\n",
    "    pipe,\n",
    "    X_train[:,filter_selected],\n",
    "    y_train,\n",
    "    X_test[:,filter_selected],\n",
    "    y_test,\n",
    "    {\n",
    "        'svc__degree': np.arange(1,5),\n",
    "        'svc__gamma': [1/X_train.shape[1]] + list(np.arange(.1, 1.1, .1)),\n",
    "        'svc__C': [.5, 1, 5, 10]\n",
    "    }\n",
    ")\n",
    "\n",
    "pipe = pipe.set_params(**params)\n",
    "\n",
    "tests = run_tests(pipe, X_train[:,filter_selected], y_train, X_test[:,filter_selected], y_test, 1)\n",
    "tests.insert(0, 'Interval 2')\n",
    "tests.insert(1, params)\n",
    "tests.insert(2, 'CCSA Filter')\n",
    "results.append(tests)\n",
    "\n",
    "dump_results(results, 'svm_int2.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ebed78",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71183c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "params, _ = find_best_params(\n",
    "    model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    {\n",
    "        'max_depth': np.arange(1, 20),\n",
    "        'n_estimators': [20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    }\n",
    ")\n",
    "\n",
    "model.set_params(**params)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "tests = run_tests(model, X_train, y_train, X_test, y_test, 50)\n",
    "tests.insert(0, 'Interval 2')\n",
    "tests.insert(1, params)\n",
    "tests.insert(2, 'All Features')\n",
    "results.append(tests)\n",
    "\n",
    "params, _ = find_best_params(\n",
    "    model,\n",
    "    X_train[:,filter_selected],\n",
    "    y_train,\n",
    "    X_test[:,filter_selected],\n",
    "    y_test,\n",
    "    {\n",
    "        'max_depth': np.arange(1, 20),\n",
    "        'n_estimators': [20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    }\n",
    ")\n",
    "\n",
    "model.set_params(**params)\n",
    "\n",
    "tests = run_tests(model, X_train[:,filter_selected], y_train, X_test[:,filter_selected], y_test, 50)\n",
    "tests.insert(0, 'Interval 2')\n",
    "tests.insert(1, params)\n",
    "tests.insert(2, 'CCSA Filter')\n",
    "results.append(tests)\n",
    "\n",
    "dump_results(results, 'rnd_forest_int2.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81449c14",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afaa37c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "\n",
    "params, _ = find_best_params(\n",
    "    model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    {\n",
    "        'max_depth': np.arange(1, 20),\n",
    "        'n_estimators': [20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    }\n",
    ")\n",
    "\n",
    "model.set_params(**params)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "tests = run_tests(model, X_train, y_train, X_test, y_test, 50)\n",
    "tests.insert(0, 'Interval 2')\n",
    "tests.insert(1, params)\n",
    "tests.insert(2, 'All Features')\n",
    "results.append(tests)\n",
    "\n",
    "params, _ = find_best_params(\n",
    "    model,\n",
    "    X_train[:,filter_selected],\n",
    "    y_train,\n",
    "    X_test[:,filter_selected],\n",
    "    y_test,\n",
    "    {\n",
    "        'max_depth': np.arange(1, 20),\n",
    "        'n_estimators': [20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    }\n",
    ")\n",
    "\n",
    "model.set_params(**params)\n",
    "\n",
    "tests = run_tests(model, X_train[:,filter_selected], y_train, X_test[:,filter_selected], y_test, 50)\n",
    "tests.insert(0, 'Interval 2')\n",
    "tests.insert(1, params)\n",
    "tests.insert(2, 'CCSA Filter')\n",
    "results.append(tests)\n",
    "\n",
    "dump_results(results, 'extrees_int2.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e621ac7",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82ff47a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "n_layers = np.arange(2) + 1\n",
    "n_neurons = np.arange(0, 35, 5) + 5\n",
    "epochs = [20, 100, 200, 300, 400, 500]\n",
    "combinations = []\n",
    "\n",
    "for layers in n_layers:\n",
    "    combinations.extend(combinations_with_replacement(n_neurons, int(layers)))\n",
    "    \n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    MLPClassifier(solver='adam', activation='tanh', learning_rate='adaptive')\n",
    ")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    \n",
    "    params, _ = find_best_params(\n",
    "        pipe,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        {\n",
    "            'mlpclassifier__hidden_layer_sizes': combinations,\n",
    "            'mlpclassifier__max_iter': epochs\n",
    "        }\n",
    "    )\n",
    "\n",
    "    pipe = pipe.set_params(**params)\n",
    "\n",
    "    tests = run_tests(pipe, X_train, y_train, X_test, y_test, 50)\n",
    "    tests.insert(0, 'Interval 2')\n",
    "    tests.insert(1, params)\n",
    "    tests.insert(2, 'All Features')\n",
    "    results.append(tests)\n",
    "    \n",
    "    params, _ = find_best_params(\n",
    "        pipe,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        {\n",
    "            'mlpclassifier__hidden_layer_sizes': combinations,\n",
    "            'mlpclassifier__max_iter': epochs\n",
    "        }\n",
    "    )\n",
    "\n",
    "    pipe = pipe.set_params(**params)\n",
    "    \n",
    "    tests = run_tests(pipe, X_train[:,filter_selected], y_train, X_test[:,filter_selected], y_test, 50)\n",
    "    tests.insert(0, 'Interval 2')\n",
    "    tests.insert(1, params)\n",
    "    tests.insert(2, 'CCSA Filter')\n",
    "    results.append(tests)\n",
    "\n",
    "    dump_results(results, 'mlp_int2.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd012db6",
   "metadata": {},
   "source": [
    "### Ensemble 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39d7079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "n_layers = np.arange(2) + 1\n",
    "n_neurons = np.arange(0, 35, 5) + 5\n",
    "epochs = [20, 100, 200, 300, 400, 500]\n",
    "combinations = []\n",
    "\n",
    "for layers in n_layers:\n",
    "    combinations.extend(combinations_with_replacement(n_neurons, int(layers)))\n",
    "    \n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    Ensemble1()\n",
    ")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    params, _ = find_best_params(\n",
    "        pipe,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        {\n",
    "            'ensemble1__mlp_hidden_layers_sizes': combinations,\n",
    "            'ensemble1__epochs': epochs\n",
    "        }\n",
    "    )\n",
    "\n",
    "    pipe = pipe.set_params(**params)\n",
    "\n",
    "    tests = run_tests(pipe, X_train, y_train, X_test, y_test, 50)\n",
    "    tests.insert(0, 'Interval 2')\n",
    "    tests.insert(1, params)\n",
    "    tests.insert(2, 'All Features')\n",
    "    results.append(tests)\n",
    "    \n",
    "    params, _ = find_best_params(\n",
    "        pipe,\n",
    "        X_train[:,filter_selected],\n",
    "        y_train,\n",
    "        X_test[:,filter_selected],\n",
    "        y_test,\n",
    "        {\n",
    "            'ensemble1__mlp_hidden_layers_sizes': combinations,\n",
    "            'ensemble1__epochs': epochs\n",
    "        }\n",
    "    )\n",
    "\n",
    "    pipe = pipe.set_params(**params)\n",
    "    \n",
    "    tests = run_tests(pipe, X_train[:,filter_selected], y_train, X_test[:,filter_selected], y_test, 50)\n",
    "    tests.insert(0, 'Interval 2')\n",
    "    tests.insert(1, params)\n",
    "    tests.insert(2, 'CCSA Filter')\n",
    "    results.append(tests)\n",
    "    \n",
    "    dump_results(results, 'ensemble1_int2.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9951dcc",
   "metadata": {},
   "source": [
    "### Ensemble 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c5fa46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "n_layers = np.arange(2) + 1\n",
    "n_neurons = np.arange(0, 35, 5) + 5\n",
    "epochs = [20, 100, 200, 300, 400, 500]\n",
    "combinations = []\n",
    "\n",
    "for layers in n_layers:\n",
    "    combinations.extend(combinations_with_replacement(n_neurons, int(layers)))\n",
    "    \n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    Ensemble2()\n",
    ")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    params, _ = find_best_params(\n",
    "        pipe,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        {\n",
    "            'ensemble2__mlp_hidden_layers_sizes': combinations,\n",
    "            'ensemble2__epochs': epochs\n",
    "        }\n",
    "    )\n",
    "\n",
    "    pipe = pipe.set_params(**params)\n",
    "\n",
    "    tests = run_tests(pipe, X_train, y_train, X_test, y_test, 50)\n",
    "    tests.insert(0, 'Interval 2')\n",
    "    tests.insert(1, params)\n",
    "    tests.insert(2, 'All Features')\n",
    "    results.append(tests)\n",
    "    \n",
    "    params, _ = find_best_params(\n",
    "        pipe,\n",
    "        X_train[:,filter_selected],\n",
    "        y_train,\n",
    "        X_test[:,filter_selected],\n",
    "        y_test,\n",
    "        {\n",
    "            'ensemble2__mlp_hidden_layers_sizes': combinations,\n",
    "            'ensemble2__epochs': epochs\n",
    "        }\n",
    "    )\n",
    "\n",
    "    pipe = pipe.set_params(**params)\n",
    "    \n",
    "    tests = run_tests(pipe, X_train[:,filter_selected], y_train, X_test[:,filter_selected], y_test, 50)\n",
    "    tests.insert(0, 'Interval 2')\n",
    "    tests.insert(1, params)\n",
    "    tests.insert(2, 'CCSA Filter')\n",
    "    results.append(tests)\n",
    "    \n",
    "    dump_results(results, 'ensemble2_int2.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaebf07-16df-4971-b275-efc0ffc6bc24",
   "metadata": {},
   "source": [
    "# Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28c60cfd-3a7e-4680-85f4-27cf68ba8fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_results = load_results()\n",
    "results_table = pd.DataFrame(loaded_results, columns=['Interval', 'Params', 'Feature Selection', 'Model', 'auc_mu', 'auc_std', 'acc_mu', 'acc_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "658c6a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table.to_excel('experiments/results_table.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04674f6f-e19e-4240-9c21-e3ab644b6554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_name(x):\n",
    "    if isinstance(x, str):\n",
    "        return x\n",
    "    elif isinstance(x, Pipeline):\n",
    "        return list(dict(x.named_steps).values())[-1]\n",
    "    else:\n",
    "        return type(x).__name__\n",
    "    \n",
    "results_table['Model'] = results_table['Model'].apply(extract_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3df2b22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interval</th>\n",
       "      <th>Params</th>\n",
       "      <th>Feature Selection</th>\n",
       "      <th>Model</th>\n",
       "      <th>auc_mu</th>\n",
       "      <th>auc_std</th>\n",
       "      <th>acc_mu</th>\n",
       "      <th>acc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Interval 1</td>\n",
       "      <td>{'ensemble1__mlp_hidden_layers_sizes': (10, 10...</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Ensemble1</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.04</td>\n",
       "      <td>50.70</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Interval 1</td>\n",
       "      <td>{'ensemble1__mlp_hidden_layers_sizes': (20, 30...</td>\n",
       "      <td>CCSA Filter</td>\n",
       "      <td>Ensemble1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.03</td>\n",
       "      <td>48.24</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Interval 1</td>\n",
       "      <td>{'ensemble2__mlp_hidden_layers_sizes': (10, 15...</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Ensemble2</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.03</td>\n",
       "      <td>50.63</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Interval 1</td>\n",
       "      <td>{'ensemble2__mlp_hidden_layers_sizes': (20, 35...</td>\n",
       "      <td>CCSA Filter</td>\n",
       "      <td>Ensemble2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.03</td>\n",
       "      <td>48.80</td>\n",
       "      <td>5.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Interval 1</td>\n",
       "      <td>{'max_depth': 14, 'n_estimators': 60}</td>\n",
       "      <td>All Features</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.02</td>\n",
       "      <td>54.22</td>\n",
       "      <td>3.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Interval 1</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 90}</td>\n",
       "      <td>CCSA Filter</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.01</td>\n",
       "      <td>56.76</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Interval 1</td>\n",
       "      <td>{'mlpclassifier__hidden_layer_sizes': (5, 5), ...</td>\n",
       "      <td>All Features</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.03</td>\n",
       "      <td>51.91</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Interval 1</td>\n",
       "      <td>{'mlpclassifier__hidden_layer_sizes': (35, 35)...</td>\n",
       "      <td>CCSA Filter</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.03</td>\n",
       "      <td>51.28</td>\n",
       "      <td>6.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Interval 1</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 100}</td>\n",
       "      <td>All Features</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.01</td>\n",
       "      <td>57.12</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Interval 1</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 90}</td>\n",
       "      <td>CCSA Filter</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.01</td>\n",
       "      <td>57.47</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Interval 1</td>\n",
       "      <td>{'svc__degree': 1, 'svc__gamma': 0.30000000000...</td>\n",
       "      <td>All Features</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.39</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Interval 1</td>\n",
       "      <td>{'svc__degree': 1, 'svc__gamma': 0.2, 'svc__C'...</td>\n",
       "      <td>CCSA Filter</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.39</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Interval 2</td>\n",
       "      <td>{'ensemble1__mlp_hidden_layers_sizes': (10, 20...</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Ensemble1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.03</td>\n",
       "      <td>49.78</td>\n",
       "      <td>5.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Interval 2</td>\n",
       "      <td>{'ensemble1__mlp_hidden_layers_sizes': (35,), ...</td>\n",
       "      <td>CCSA Filter</td>\n",
       "      <td>Ensemble1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.03</td>\n",
       "      <td>51.92</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Interval 2</td>\n",
       "      <td>{'ensemble2__mlp_hidden_layers_sizes': (20, 25...</td>\n",
       "      <td>All Features</td>\n",
       "      <td>Ensemble2</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.03</td>\n",
       "      <td>52.38</td>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Interval 2</td>\n",
       "      <td>{'ensemble2__mlp_hidden_layers_sizes': (15, 15...</td>\n",
       "      <td>CCSA Filter</td>\n",
       "      <td>Ensemble2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.04</td>\n",
       "      <td>51.52</td>\n",
       "      <td>6.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Interval 2</td>\n",
       "      <td>{'max_depth': 14, 'n_estimators': 50}</td>\n",
       "      <td>All Features</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.02</td>\n",
       "      <td>55.45</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Interval 2</td>\n",
       "      <td>{'max_depth': 9, 'n_estimators': 70}</td>\n",
       "      <td>CCSA Filter</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>57.97</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Interval 2</td>\n",
       "      <td>{'mlpclassifier__hidden_layer_sizes': (30,), '...</td>\n",
       "      <td>All Features</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.03</td>\n",
       "      <td>55.36</td>\n",
       "      <td>5.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Interval 2</td>\n",
       "      <td>{'mlpclassifier__hidden_layer_sizes': (35, 35)...</td>\n",
       "      <td>CCSA Filter</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>58.17</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Interval 2</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 60}</td>\n",
       "      <td>All Features</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.02</td>\n",
       "      <td>57.19</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Interval 2</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 80}</td>\n",
       "      <td>CCSA Filter</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.02</td>\n",
       "      <td>56.25</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Interval 2</td>\n",
       "      <td>{'svc__degree': 3, 'svc__gamma': 0.01123595505...</td>\n",
       "      <td>All Features</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.24</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Interval 2</td>\n",
       "      <td>{'svc__degree': 1, 'svc__gamma': 0.2, 'svc__C'...</td>\n",
       "      <td>CCSA Filter</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.94</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Interval                                             Params  \\\n",
       "14  Interval 1  {'ensemble1__mlp_hidden_layers_sizes': (10, 10...   \n",
       "15  Interval 1  {'ensemble1__mlp_hidden_layers_sizes': (20, 30...   \n",
       "4   Interval 1  {'ensemble2__mlp_hidden_layers_sizes': (10, 15...   \n",
       "5   Interval 1  {'ensemble2__mlp_hidden_layers_sizes': (20, 35...   \n",
       "10  Interval 1              {'max_depth': 14, 'n_estimators': 60}   \n",
       "11  Interval 1               {'max_depth': 5, 'n_estimators': 90}   \n",
       "22  Interval 1  {'mlpclassifier__hidden_layer_sizes': (5, 5), ...   \n",
       "23  Interval 1  {'mlpclassifier__hidden_layer_sizes': (35, 35)...   \n",
       "16  Interval 1              {'max_depth': 2, 'n_estimators': 100}   \n",
       "17  Interval 1               {'max_depth': 2, 'n_estimators': 90}   \n",
       "8   Interval 1  {'svc__degree': 1, 'svc__gamma': 0.30000000000...   \n",
       "9   Interval 1  {'svc__degree': 1, 'svc__gamma': 0.2, 'svc__C'...   \n",
       "18  Interval 2  {'ensemble1__mlp_hidden_layers_sizes': (10, 20...   \n",
       "19  Interval 2  {'ensemble1__mlp_hidden_layers_sizes': (35,), ...   \n",
       "6   Interval 2  {'ensemble2__mlp_hidden_layers_sizes': (20, 25...   \n",
       "7   Interval 2  {'ensemble2__mlp_hidden_layers_sizes': (15, 15...   \n",
       "12  Interval 2              {'max_depth': 14, 'n_estimators': 50}   \n",
       "13  Interval 2               {'max_depth': 9, 'n_estimators': 70}   \n",
       "20  Interval 2  {'mlpclassifier__hidden_layer_sizes': (30,), '...   \n",
       "21  Interval 2  {'mlpclassifier__hidden_layer_sizes': (35, 35)...   \n",
       "2   Interval 2               {'max_depth': 3, 'n_estimators': 60}   \n",
       "3   Interval 2               {'max_depth': 4, 'n_estimators': 80}   \n",
       "0   Interval 2  {'svc__degree': 3, 'svc__gamma': 0.01123595505...   \n",
       "1   Interval 2  {'svc__degree': 1, 'svc__gamma': 0.2, 'svc__C'...   \n",
       "\n",
       "   Feature Selection                   Model  auc_mu  auc_std  acc_mu  acc_std  \n",
       "14      All Features               Ensemble1    0.51     0.04   50.70     6.05  \n",
       "15       CCSA Filter               Ensemble1    0.50     0.03   48.24     6.20  \n",
       "4       All Features               Ensemble2    0.51     0.03   50.63     6.20  \n",
       "5        CCSA Filter               Ensemble2    0.50     0.03   48.80     5.51  \n",
       "10      All Features    ExtraTreesClassifier    0.50     0.02   54.22     3.16  \n",
       "11       CCSA Filter    ExtraTreesClassifier    0.51     0.01   56.76     1.82  \n",
       "22      All Features           MLPClassifier    0.49     0.03   51.91     5.88  \n",
       "23       CCSA Filter           MLPClassifier    0.50     0.03   51.28     6.74  \n",
       "16      All Features  RandomForestClassifier    0.51     0.01   57.12     1.86  \n",
       "17       CCSA Filter  RandomForestClassifier    0.52     0.01   57.47     1.87  \n",
       "8       All Features                     SVC    0.53     0.00   60.39     0.00  \n",
       "9        CCSA Filter                     SVC    0.54     0.00   60.39     0.00  \n",
       "18      All Features               Ensemble1    0.50     0.03   49.78     5.51  \n",
       "19       CCSA Filter               Ensemble1    0.50     0.03   51.92     5.50  \n",
       "6       All Features               Ensemble2    0.51     0.03   52.38     5.74  \n",
       "7        CCSA Filter               Ensemble2    0.50     0.04   51.52     6.28  \n",
       "12      All Features    ExtraTreesClassifier    0.49     0.02   55.45     3.93  \n",
       "13       CCSA Filter    ExtraTreesClassifier    0.50     0.01   57.97     1.53  \n",
       "20      All Features           MLPClassifier    0.52     0.03   55.36     5.48  \n",
       "21       CCSA Filter           MLPClassifier    0.50     0.01   58.17     1.86  \n",
       "2       All Features  RandomForestClassifier    0.50     0.02   57.19     3.29  \n",
       "3        CCSA Filter  RandomForestClassifier    0.49     0.02   56.25     3.96  \n",
       "0       All Features                     SVC    0.60     0.00   62.24     0.00  \n",
       "1        CCSA Filter                     SVC    0.57     0.00   62.94     0.00  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_table.sort_values(['Interval', 'Model', 'Feature Selection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4627912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('mba')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "77d4e46e20c9741493d149ab557059246e1363d6acf045718aa6ae2fa8ded508"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
